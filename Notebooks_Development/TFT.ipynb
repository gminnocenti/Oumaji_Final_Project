{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from lightning.pytorch import Trainer\n",
    "from pytorch_forecasting import TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import NaNLabelEncoder\n",
    "from pytorch_forecasting.metrics import QuantileLoss\n",
    "from pytorch_forecasting.models import TemporalFusionTransformer\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "from mlflow.models import infer_signature\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"weekly_demand.csv\")\n",
    "df.head()\n",
    "df[\"semana_inicio\"] = pd.to_datetime(df[\"semana_inicio\"])\n",
    "df[\"time_idx\"] = df[\"semana_inicio\"].rank(method=\"dense\").astype(\"int\") - 1\n",
    "df[\"platillo_id\"] = df[\"platillo_id\"].astype(str)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/axllopez/Desktop/OneDrive _Instituto Tecnologico_y_de_Estudios_Superiores_de_Monterrey/OCTAVO/Proyecto IDM/Oumaji_Final_Project/.venv/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "/Users/axllopez/Desktop/OneDrive _Instituto Tecnologico_y_de_Estudios_Superiores_de_Monterrey/OCTAVO/Proyecto IDM/Oumaji_Final_Project/.venv/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/05/19 18:15:21 INFO mlflow.tracking.fluent: Experiment with name 'Oumaji_Demand' does not exist. Creating a new experiment.\n",
      "2025/05/19 18:15:21 WARNING mlflow.utils.autologging_utils: MLflow pytorch autologging is known to be compatible with 1.9.0 <= torch <= 2.6.0, but the installed version is 2.7.0. If you encounter errors during autologging, try upgrading / downgrading torch to a compatible version, or try upgrading MLflow.\n",
      "2025/05/19 18:15:21 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/Users/axllopez/Desktop/OneDrive _Instituto Tecnologico_y_de_Estudios_Superiores_de_Monterrey/OCTAVO/Proyecto IDM/Oumaji_Final_Project/.venv/lib/python3.11/site-packages/mlflow/pytorch/_lightning_autolog.py:465: UserWarning: Autologging is known to be compatible with pytorch-lightning versions between 1.9.0 and 2.5.1 and may not succeed with packages outside this range.\"\n",
      "/Users/axllopez/Desktop/OneDrive _Instituto Tecnologico_y_de_Estudios_Superiores_de_Monterrey/OCTAVO/Proyecto IDM/Oumaji_Final_Project/.venv/lib/python3.11/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/axllopez/Desktop/OneDrive _Instituto Tecnologico_y_de_Estudios_Superiores_de_Monterrey/OCTAVO/Proyecto IDM/Oumaji_Final_Project/Notebooks_Development/checkpoints exists and is not empty.\n",
      "\n",
      "   | Name                               | Type                            | Params | Mode \n",
      "------------------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0      | train\n",
      "1  | logging_metrics                    | ModuleList                      | 0      | train\n",
      "2  | input_embeddings                   | MultiEmbedding                  | 0      | train\n",
      "3  | prescalers                         | ModuleDict                      | 224    | train\n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 1.7 K  | train\n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 7.4 K  | train\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 5.1 K  | train\n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 1.1 K  | train\n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 1.1 K  | train\n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 1.1 K  | train\n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 1.1 K  | train\n",
      "11 | lstm_encoder                       | LSTM                            | 2.2 K  | train\n",
      "12 | lstm_decoder                       | LSTM                            | 2.2 K  | train\n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 544    | train\n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 32     | train\n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 1.4 K  | train\n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 1.1 K  | train\n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 576    | train\n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 1.1 K  | train\n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 576    | train\n",
      "20 | output_layer                       | Linear                          | 119    | train\n",
      "------------------------------------------------------------------------------------------------\n",
      "28.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "28.4 K    Total params\n",
      "0.113     Total estimated model params size (MB)\n",
      "477       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/axllopez/Desktop/OneDrive _Instituto Tecnologico_y_de_Estudios_Superiores_de_Monterrey/OCTAVO/Proyecto IDM/Oumaji_Final_Project/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/axllopez/Desktop/OneDrive _Instituto Tecnologico_y_de_Estudios_Superiores_de_Monterrey/OCTAVO/Proyecto IDM/Oumaji_Final_Project/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 49/49 [00:22<00:00,  2.15it/s, train_loss_step=7.420, val_loss=10.50, train_loss_epoch=7.220]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 49/49 [00:23<00:00,  2.11it/s, train_loss_step=7.420, val_loss=10.50, train_loss_epoch=7.220]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/axllopez/Desktop/OneDrive _Instituto Tecnologico_y_de_Estudios_Superiores_de_Monterrey/OCTAVO/Proyecto IDM/Oumaji_Final_Project/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "2025/05/19 18:26:53 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/05/19 18:26:54 WARNING mlflow.models.model: Failed to validate serving input example {\n",
      "  \"inputs\": {\n",
      "    \"encoder_cat\": [\n",
      "      [\n",
      "        [],\n",
      "        [],\n",
      "        [],\n",
      "        [],\n",
      "        [],\n",
      "        [],\n",
      "        [],\n",
      "        [],\n",
      "        [],\n",
      "        [],\n",
      "        [],\n",
      "        [],\n",
      "        [],\n",
      "        [],\n",
      "        [],\n",
      "        []\n",
      "      ]\n",
      "    ],\n",
      "    \"encoder_cont\": [\n",
      "      [\n",
      "        [\n",
      "          1.0,\n",
      "          2.6062135696411133,\n",
      "          3.0351369380950928,\n",
      "          0.6537204384803772,\n",
      "          1.0028178691864014,\n",
      "          1.1170096397399902,\n",
      "          1.343428611755371,\n",
      "          -0.35729479789733887,\n",
      "          -0.3900947570800781,\n",
      "          -0.73939448595047,\n",
      "          -1.0,\n",
      "          0.0,\n",
      "          1.217566967010498,\n",
      "          0.5367770791053772\n",
      "        ],\n",
      "        [\n",
      "          1.0,\n",
      "          2.6062135696411133,\n",
      "          3.0351369380950928,\n",
      "          0.7190924882888794,\n",
      "          1.0028178691864014,\n",
      "          1.1832306385040283,\n",
      "          1.343428611755371,\n",
      "          -0.35729479789733887,\n",
      "          -0.3900947570800781,\n",
      "          -1.6349434852600098,\n",
      "          -0.9375,\n",
      "          0.0,\n",
      "          1.7794636487960815,\n",
      "          1.227433204650879\n",
      "        ],\n",
      "        [\n",
      "          1.0,\n",
      "          2.6062135696411133,\n",
      "          3.0351369380950928,\n",
      "          0.7844645380973816,\n",
      "          1.2916730642318726,\n",
      "          1.2494515180587769,\n",
      "          1.343428611755371,\n",
      "          -0.35729479789733887,\n",
      "          -0.3900947570800781,\n",
      "          -0.8577041029930115,\n",
      "          -0.875,\n",
      "          0.0,\n",
      "          0.9582300782203674,\n",
      "          1.7885913848876953\n",
      "        ],\n",
      "        [\n",
      "          1.0,\n",
      "          2.6062135696411133,\n",
      "          3.0351369380950928,\n",
      "          0.8498365879058838,\n",
      "          1.2916730642318726,\n",
      "          1.315672516822815,\n",
      "          1.343428611755371,\n",
      "          -0.35729479789733887,\n",
      "          -0.3900947570800781,\n",
      "          0.3731860816478729,\n",
      "          -0.8125,\n",
      "          0.0,\n",
      "          1.7362408638000488,\n",
      "          0.9684371948242188\n",
      "        ],\n",
      "        [\n",
      "          1.0,\n",
      "          2.6062135696411133,\n",
      "          3.0351369380950928,\n",
      "          0.915208637714386,\n",
      "          1.2916730642318726,\n",
      "          1.3818933963775635,\n",
      "          1.343428611755371,\n",
      "          -0.35729479789733887,\n",
      "          2.5634796619415283,\n",
      "          0.1820102483034134,\n",
      "          -0.75,\n",
      "          0.0,\n",
      "          1.7362408638000488,\n",
      "          1.7454253435134888\n",
      "        ],\n",
      "        [\n",
      "          1.0,\n",
      "          2.6062135696411133,\n",
      "          3.0351369380950928,\n",
      "          0.9805806875228882,\n",
      "          1.2916730642318726,\n",
      "          1.448114275932312,\n",
      "          1.343428611755371,\n",
      "          -0.35729479789733887,\n",
      "          -0.3900947570800781,\n",
      "          -0.1509803980588913,\n",
      "          -0.6875,\n",
      "          0.0,\n",
      "          0.8573768138885498,\n",
      "          1.7454253435134888\n",
      "        ],\n",
      "        [\n",
      "          1.0,\n",
      "          2.6062135696411133,\n",
      "          3.0351369380950928,\n",
      "          1.0459526777267456,\n",
      "          1.5805281400680542,\n",
      "          1.51433527469635,\n",
      "          1.343428611755371,\n",
      "          -0.35729479789733887,\n",
      "          -0.3900947570800781,\n",
      "          0.30658793449401855,\n",
      "          -0.625,\n",
      "          0.0,\n",
      "          0.5548170804977417,\n",
      "          0.8677164912223816\n",
      "        ],\n",
      "        [\n",
      "          1.0,\n",
      "          2.6062135696411133,\n",
      "          3.0351369380950928,\n",
      "          1.1113247871398926,\n",
      "          1.5805281400680542,\n",
      "          1.5805561542510986,\n",
      "          1.343428611755371,\n",
      "          -0.35729479789733887,\n",
      "          -0.3900947570800781,\n",
      "          -0.49023911356925964,\n",
      "          -0.5625,\n",
      "          0.0,\n",
      "          0.7709311842918396,\n",
      "          0.5655544400215149\n",
      "        ],\n",
      "        [\n",
      "          1.0,\n",
      "          2.6062135696411133,\n",
      "          3.0351369380950928,\n",
      "          1.17669677734375,\n",
      "          1.5805281400680542,\n",
      "          1.6467771530151367,\n",
      "          1.343428611755371,\n",
      "          -0.35729479789733887,\n",
      "          -0.3900947570800781,\n",
      "          -1.4249634742736816,\n",
      "          -0.5,\n",
      "          0.0,\n",
      "          0.45396384596824646,\n",
      "          0.7813844680786133\n",
      "        ],\n",
      "        [\n",
      "          1.0,\n",
      "          2.6062135696411133,\n",
      "          3.0351369380950928,\n",
      "          1.242068886756897,\n",
      "          1.5805281400680542,\n",
      "          1.7129980325698853,\n",
      "          1.343428611755371,\n",
      "          -0.35729479789733887,\n",
      "          2.5634796619415283,\n",
      "          -0.6720128655433655,\n",
      "          -0.4375,\n",
      "          0.0,\n",
      "          0.6268551349639893,\n",
      "          0.46483373641967773\n",
      "        ],\n",
      "        [\n",
      "          1.0,\n",
      "          2.6062135696411133,\n",
      "          3.0351369380950928,\n",
      "          1.3074408769607544,\n",
      "          1.5805281400680542,\n",
      "          -1.6642694473266602,\n",
      "          1.343428611755371,\n",
      "          -0.35729479789733887,\n",
      "          2.5634796619415283,\n",
      "          -0.27555808424949646,\n",
      "          -0.375,\n",
      "          0.0,\n",
      "          3.004110097885132,\n",
      "          0.6374977827072144\n",
      "        ],\n",
      "        [\n",
      "          1.0,\n",
      "          2.6062135696411133,\n",
      "          3.0351369380950928,\n",
      "          1.3728129863739014,\n",
      "          -1.5968784093856812,\n",
      "          -1.5980485677719116,\n",
      "          -1.3604340553283691,\n",
      "          2.798809289932251,\n",
      "          -0.3900947570800781,\n",
      "          0.7665067911148071,\n",
      "          -0.3125,\n",
      "          -1.0,\n",
      "          1.5057190656661987,\n",
      "          3.0116283893585205\n",
      "        ],\n",
      "        [\n",
      "          1.0,\n",
      "          2.6062135696411133,\n",
      "          3.0351369380950928,\n",
      "          1.4381849765777588,\n",
      "          -1.5968784093856812,\n",
      "          -1.5318275690078735,\n",
      "          -1.3604340553283691,\n",
      "          2.798809289932251,\n",
      "          -0.3900947570800781,\n",
      "          0.2619280219078064,\n",
      "          -0.25,\n",
      "          0.0,\n",
      "          0.39633339643478394,\n",
      "          1.5152066946029663\n",
      "        ],\n",
      "        [\n",
      "          1.0,\n",
      "          2.6062135696411133,\n",
      "          3.0351369380950928,\n",
      "          1.5035570859909058,\n",
      "          -1.5968784093856812,\n",
      "          -1.465606689453125,\n",
      "          -1.3604340553283691,\n",
      "          2.798809289932251,\n",
      "          -0.3900947570800781,\n",
      "          0.5071658492088318,\n",
      "          -0.1875,\n",
      "          0.0,\n",
      "          0.7853387594223022,\n",
      "          0.40727904438972473\n",
      "        ],\n",
      "        [\n",
      "          1.0,\n",
      "          2.6062135696411133,\n",
      "          3.0351369380950928,\n",
      "          1.5689290761947632,\n",
      "          -1.5968784093856812,\n",
      "          -1.399385690689087,\n",
      "          -1.3604340553283691,\n",
      "          2.798809289932251,\n",
      "          -0.3900947570800781,\n",
      "          0.14126786589622498,\n",
      "          -0.125,\n",
      "          0.0,\n",
      "          0.6556703448295593,\n",
      "          0.7957731485366821\n",
      "        ],\n",
      "        [\n",
      "          1.0,\n",
      "          2.6062135696411133,\n",
      "          3.0351369380950928,\n",
      "          1.6343011856079102,\n",
      "          -1.3080233335494995,\n",
      "          -1.3331648111343384,\n",
      "          -1.3604340553283691,\n",
      "          2.798809289932251,\n",
      "          2.5634796619415283,\n",
      "          -1.1844266653060913,\n",
      "          -0.0625,\n",
      "          0.0,\n",
      "          0.5692247152328491,\n",
      "          0.666275143623352\n",
      "        ]\n",
      "      ]\n",
      "    ],\n",
      "    \"encoder_target\": [\n",
      "      [\n",
      "        176,\n",
      "        119,\n",
      "        173,\n",
      "        173,\n",
      "        112,\n",
      "        91,\n",
      "        106,\n",
      "        84,\n",
      "        96,\n",
      "        261,\n",
      "        157,\n",
      "        80,\n",
      "        107,\n",
      "        98,\n",
      "        92,\n",
      "        88\n",
      "      ]\n",
      "    ],\n",
      "    \"encoder_lengths\": [\n",
      "      16\n",
      "    ],\n",
      "    \"decoder_cat\": [\n",
      "      [\n",
      "        [],\n",
      "        [],\n",
      "        [],\n",
      "        []\n",
      "      ]\n",
      "    ],\n",
      "    \"decoder_cont\": [\n",
      "      [\n",
      "        [\n",
      "          1.0,\n",
      "          2.6062135696411133,\n",
      "          3.0351369380950928,\n",
      "          1.6996731758117676,\n",
      "          -1.3080233335494995,\n",
      "          -1.2669438123703003,\n",
      "          -1.3604340553283691,\n",
      "          2.798809289932251,\n",
      "          -0.3900947570800781,\n",
      "          -1.6631497144699097,\n",
      "          0.0,\n",
      "          0.0,\n",
      "          0.5115942358970642,\n",
      "          0.5799431204795837\n",
      "        ],\n",
      "        [\n",
      "          1.0,\n",
      "          2.6062135696411133,\n",
      "          3.0351369380950928,\n",
      "          1.765045166015625,\n",
      "          -1.3080233335494995,\n",
      "          -1.2007229328155518,\n",
      "          -1.3604340553283691,\n",
      "          2.798809289932251,\n",
      "          -0.3900947570800781,\n",
      "          -0.45028024911880493,\n",
      "          0.0625,\n",
      "          0.0,\n",
      "          0.9294148683547974,\n",
      "          0.5223883986473083\n",
      "        ],\n",
      "        [\n",
      "          1.0,\n",
      "          2.6062135696411133,\n",
      "          3.0351369380950928,\n",
      "          1.830417275428772,\n",
      "          -1.3080233335494995,\n",
      "          -1.1345019340515137,\n",
      "          -1.3604340553283691,\n",
      "          2.798809289932251,\n",
      "          -0.3900947570800781,\n",
      "          -0.4698679447174072,\n",
      "          0.125,\n",
      "          0.0,\n",
      "          1.0158604383468628,\n",
      "          0.939659833908081\n",
      "        ],\n",
      "        [\n",
      "          1.0,\n",
      "          2.6062135696411133,\n",
      "          3.0351369380950928,\n",
      "          1.8957892656326294,\n",
      "          -1.0191681385040283,\n",
      "          -1.0682810544967651,\n",
      "          -1.3604340553283691,\n",
      "          2.798809289932251,\n",
      "          -0.3900947570800781,\n",
      "          -0.25597038865089417,\n",
      "          0.1875,\n",
      "          0.0,\n",
      "          1.0878984928131104,\n",
      "          1.0259919166564941\n",
      "        ]\n",
      "      ]\n",
      "    ],\n",
      "    \"decoder_target\": [\n",
      "      [\n",
      "        117,\n",
      "        123,\n",
      "        128,\n",
      "        116\n",
      "      ]\n",
      "    ],\n",
      "    \"decoder_lengths\": [\n",
      "      4\n",
      "    ],\n",
      "    \"decoder_time_idx\": [\n",
      "      [\n",
      "        52,\n",
      "        53,\n",
      "        54,\n",
      "        55\n",
      "      ]\n",
      "    ],\n",
      "    \"groups\": [\n",
      "      [\n",
      "        0\n",
      "      ]\n",
      "    ],\n",
      "    \"target_scale\": [\n",
      "      [\n",
      "        200.1132049560547,\n",
      "        119.11689758300781\n",
      "      ]\n",
      "    ]\n",
      "  }\n",
      "}. Alternatively, you can avoid passing input example and pass model signature instead when logging the model. To ensure the input example is valid prior to serving, please try calling `mlflow.models.validate_serving_input` on the model uri and serving input example. A serving input example can be generated from model input example using `mlflow.models.convert_input_example_to_serving_input` function.\n",
      "Got error: The PyTorch flavor does not support List or Dict input types. Please use a pandas.DataFrame or a numpy.ndarray\n",
      "Successfully registered model 'TFT'.\n",
      "2025/05/19 18:26:54 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: TFT, version 1\n",
      "Created version '1' of model 'TFT'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run illustrious-asp-80 at: http://localhost:5001/#/experiments/400716610318719328/runs/b82175e0e93f4c9896edd58b19156386\n",
      "🧪 View experiment at: http://localhost:5001/#/experiments/400716610318719328\n"
     ]
    }
   ],
   "source": [
    "hp = dict(\n",
    "    # datos\n",
    "    batch_size            = 64,\n",
    "    max_encoder_length    = 16,\n",
    "    max_prediction_length = 4,\n",
    "    # modelo TFT\n",
    "    learning_rate         = 1e-3,\n",
    "    hidden_size           = 16,\n",
    "    lstm_layers           = 1,\n",
    "    attention_head_size   = 1,\n",
    "    hidden_cont_size      = 8,   # tamaño de capas para variables continuas\n",
    "    dropout               = 0.1,\n",
    "    loss_fn               = \"QuantileLoss\",\n",
    "    # entrenamiento\n",
    "    max_epochs            = 30,\n",
    "    gradient_clip_val     = 0.1,\n",
    "    reduce_patience       = 4,\n",
    ")\n",
    "\n",
    "quantiles = [0.1, 0.5, 0.9]\n",
    "\n",
    "training_cutoff = df[\"time_idx\"].max() - hp[\"max_prediction_length\"]\n",
    "train_df = df[df.time_idx <= training_cutoff].copy()\n",
    "val_df   = df[df.time_idx >= training_cutoff - hp[\"max_encoder_length\"]].copy()\n",
    "\n",
    "common = dict(\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"cantidad\",\n",
    "    group_ids=[\"platillo_id\"],\n",
    "    max_encoder_length=hp[\"max_encoder_length\"],\n",
    "    max_prediction_length=hp[\"max_prediction_length\"],\n",
    "    time_varying_known_reals=[\n",
    "        \"time_idx\", \"mes\", \"semana_ano\", \"trimestre\", \"ano\",\n",
    "        \"dia_festivo\", \"ocupacion\"\n",
    "    ],\n",
    "    time_varying_unknown_reals=[\"cantidad\", \"lag_1\", \"lag_2\"],\n",
    "    target_normalizer=GroupNormalizer(groups=[\"platillo_id\"]),\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    add_encoder_length=True,\n",
    "    allow_missing_timesteps=True,\n",
    ")\n",
    "\n",
    "training_ds   = TimeSeriesDataSet(train_df, **common)\n",
    "validation_ds = TimeSeriesDataSet.from_dataset(training_ds, val_df, stop_randomization=True)\n",
    "\n",
    "train_loader = training_ds.to_dataloader(train=True , batch_size=hp[\"batch_size\"], num_workers=0)\n",
    "val_loader   = validation_ds.to_dataloader(train=False, batch_size=hp[\"batch_size\"], num_workers=0)\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training_ds,\n",
    "    learning_rate        = hp[\"learning_rate\"],\n",
    "    hidden_size          = hp[\"hidden_size\"],\n",
    "    lstm_layers          = hp[\"lstm_layers\"],\n",
    "    attention_head_size  = hp[\"attention_head_size\"],\n",
    "    hidden_continuous_size = hp[\"hidden_cont_size\"],\n",
    "    dropout              = hp[\"dropout\"],\n",
    "    loss                 = QuantileLoss(),\n",
    "    log_interval         = 10,\n",
    "    reduce_on_plateau_patience = hp[\"reduce_patience\"],\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs         = hp[\"max_epochs\"],\n",
    "    gradient_clip_val  = hp[\"gradient_clip_val\"],\n",
    "    logger             = False,        # usamos MLflow autolog\n",
    "    deterministic      = True,\n",
    ")\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://localhost:5001\")\n",
    "mlflow.set_experiment(\"Oumaji_Demand\")\n",
    "mlflow.pytorch.autolog(log_every_n_epoch=1, log_models=False)\n",
    "\n",
    "with mlflow.start_run():\n",
    "    # ---------- PARAMS ----------\n",
    "    mlflow.log_params({f\"data.{k}\": v for k, v in hp.items()})\n",
    "    # ---------- ENTRENAMIENTO ----\n",
    "    trainer.fit(tft, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
    "    # ---------- VALIDACIÓN ----\n",
    "    pred_q, row_idx, *_ = tft.predict(\n",
    "    val_loader,\n",
    "    mode=\"quantiles\",\n",
    "    mode_kwargs={\"quantiles\": quantiles},\n",
    "    return_index=True,\n",
    "    return_x=True,  \n",
    "    return_y=False,\n",
    "    return_decoder_lengths=False,\n",
    ")\n",
    "\n",
    "    # —— reconstruir DataFrame ——\n",
    "    time_map = df[[\"time_idx\", \"semana_inicio\"]].drop_duplicates().set_index(\"time_idx\")[\"semana_inicio\"]\n",
    "    dec_idx  = row_idx[\"decoder_time_idx\"].flatten().cpu().numpy().astype(int)\n",
    "    cat_codes = row_idx[\"groups\"][..., 0].flatten().cpu().numpy()\n",
    "    horiz     = pred_q.shape[1]\n",
    "    pred_np   = pred_q.cpu().numpy().reshape(-1, pred_q.shape[-1])\n",
    "    cat_rep   = np.repeat(cat_codes, horiz)\n",
    "    code_to_id = dict(enumerate(df[\"platillo_id\"].astype(\"category\").cat.categories))\n",
    "    plat_ids   = [code_to_id[c] for c in cat_rep]\n",
    "\n",
    "    val_out = pd.DataFrame({\n",
    "    \"platillo_id\": plat_ids,\n",
    "    \"semana_pred\": time_map.loc[dec_idx].values,\n",
    "    \"p10\": np.round(pred_np[:, 0], 2),\n",
    "    \"p50\": np.round(pred_np[:, 1], 2),\n",
    "    \"p90\": np.round(pred_np[:, 2], 2),\n",
    "    })\n",
    "    \n",
    "    y_true = (\n",
    "        df.set_index([\"platillo_id\", \"time_idx\"])\n",
    "          .loc[list(zip(val_out[\"platillo_id\"], dec_idx)), \"cantidad\"]\n",
    "          .values\n",
    "    )\n",
    "    val_out[\"cantidad\"] = y_true\n",
    "\n",
    "    mae = mean_absolute_error(val_out[\"cantidad\"], val_out[\"p50\"])\n",
    "    coverage = ((val_out[\"cantidad\"] >= val_out[\"p10\"]) &\n",
    "                (val_out[\"cantidad\"] <= val_out[\"p90\"])).mean()\n",
    "\n",
    "    # ---------- MÉTRICAS ----------\n",
    "    mlflow.log_metrics({\n",
    "        \"MAE_holdout\": mae,\n",
    "        \"p90_coverage\": coverage,\n",
    "    })\n",
    "\n",
    "    # ---------------- SIGNATURE + MODELO ----------------\n",
    "    x_batch, _ = next(iter(val_loader))\n",
    "    x_example_np = {k: v[:1].cpu().numpy() for k, v in x_batch.items()}\n",
    "\n",
    "    y_pred_np = np.zeros((1, hp[\"max_prediction_length\"] * len(quantiles)), dtype=np.float32)\n",
    "\n",
    "    signature = infer_signature(x_example_np, y_pred_np)\n",
    "\n",
    "    mlflow.pytorch.log_model(\n",
    "        pytorch_model=tft,\n",
    "        artifact_path=\"model\",\n",
    "        signature=signature,\n",
    "        input_example=x_example_np,\n",
    "        registered_model_name=\"TFT\",\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    # ---------- ARTIFACTOS -------\n",
    "    ckpt = trainer.checkpoint_callback.best_model_path\n",
    "    if ckpt:\n",
    "        mlflow.log_artifact(ckpt, artifact_path=\"checkpoints\")\n",
    "\n",
    "    val_out.to_csv(\"val_out.csv\", index=False)\n",
    "    mlflow.log_artifact(\"val_out.csv\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             run_id  metrics.MPE_holdout  metrics.val_RMSE  \\\n",
      "0  329315f89fa140659dfcfc1f75d78483                  NaN         32.543385   \n",
      "1  190652c4253e470e9362deeec98e2160                  NaN         32.018600   \n",
      "2  e0ec57062fac42fa9a5113ab83e6cdd6                  NaN         33.529804   \n",
      "3  5110704bfbb84ff6833febf47fb102be                  NaN         31.776373   \n",
      "4  96204246010d4ee290a76dc6e7344f5b                  NaN         31.068344   \n",
      "5  fe8872652c464a0e80aa403f4bb67702                  NaN         33.158695   \n",
      "6  724a93ea7865493481439186f3282889                  NaN         32.286457   \n",
      "7  cc9e1af8b74c481ea1b45a5329514d3b                  NaN         33.020603   \n",
      "\n",
      "   metrics.val_loss  metrics.p90_coverage  metrics.val_SMAPE  metrics.val_MAE  \\\n",
      "0         10.487294              0.201613           0.470246        16.831039   \n",
      "1         10.373519              0.198925           0.457364        16.294785   \n",
      "2         10.451321              0.196237           0.496352        17.057072   \n",
      "3         10.200771              0.280914           0.453422        16.611170   \n",
      "4          9.533278              0.145161           0.485446        16.141590   \n",
      "5         10.284668              0.151882           0.471347        16.530741   \n",
      "6         10.062208              0.153226           0.518796        16.909292   \n",
      "7         10.624692              0.228495           0.464947        16.567339   \n",
      "\n",
      "   metrics.train_loss  metrics.MAE_holdout  metrics.train_loss_step  \\\n",
      "0            8.430154            28.443508                10.206524   \n",
      "1            8.543073            24.750000                 7.495683   \n",
      "2            8.628031            26.219086                 8.488150   \n",
      "3            8.478293            21.524879                 7.118596   \n",
      "4            8.547900            25.735888                 7.538175   \n",
      "5            8.668682            26.548670                 8.058374   \n",
      "6            9.602058            25.286076                 7.412890   \n",
      "7            7.140797            23.635029                 7.513324   \n",
      "\n",
      "   metrics.val_MAPE  metrics.train_loss_epoch  \n",
      "0        35622240.0                  8.430154  \n",
      "1        34707904.0                  8.543073  \n",
      "2        33405138.0                  8.628031  \n",
      "3        45385564.0                  8.478293  \n",
      "4        21950566.0                  8.547900  \n",
      "5        30162646.0                  8.668682  \n",
      "6        32288290.0                  9.602058  \n",
      "7        24911822.0                  7.140797  \n"
     ]
    }
   ],
   "source": [
    "exp_id = \"710601173413351203\"                 # tu experimento\n",
    "df_runs = mlflow.search_runs(experiment_ids=[exp_id])\n",
    "\n",
    "bad = df_runs[df_runs.filter(regex=\"metrics.\").isna().any(axis=1)]\n",
    "print(bad[['run_id'] + [c for c in bad.columns if c.startswith(\"metrics.\")]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
